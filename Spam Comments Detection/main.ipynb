{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YouTube Spam Comments Detection\n",
    "\n",
    "This project aims to detect spam comments on YouTube using the Naive Bayes algorithm, specifically the BernoulliNB model. Spam detection is important for maintaining the quality and integrity of online platforms, and YouTube is no exception. In this project, we use a dataset containing YouTube comments and a binary label (Spam or Not Spam) to build a machine learning model for classification.\n",
    "\n",
    "`Author:` [Syed Muhammad Ebad](https://www.kaggle.com/syedmuhammadebad)\\\n",
    "`Date:` 14-Sept-2024\\\n",
    "[Send me an email](mailto:mohammadebad1@hotmail.com)\\\n",
    "[Visit my GitHub profile](https://github.com/smebad)\n",
    "\n",
    "[Dataset used in this notebook](https://www.kaggle.com/datasets/lakshmi25npathi/images?resource=download)\n",
    "\n",
    "## Dataset Description\n",
    "The dataset contains the following key columns:\n",
    "- `CONTENT`: The actual text of the YouTube comment.\n",
    "- `CLASS`: A binary label indicating whether the comment is spam (1) or not spam (0).\n",
    "\n",
    "The dataset consists of YouTube comments from popular videos. Our goal is to classify the comments into two categories: \"Spam\" or \"Not Spam\".\n",
    "\n",
    "## Steps to Build the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import Libraries\n",
    "We start by importing the necessary libraries, including Pandas and NumPy for data manipulation, and libraries from Scikit-learn for vectorizing text data, splitting the dataset, and implementing the Naive Bayes model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import BernoulliNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Import and Review the Dataset\n",
    "Load the dataset into a DataFrame and take a look at the first few rows to understand the structure of the data. We will also review the data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    COMMENT_ID            AUTHOR  \\\n",
      "0  LZQPQhLyRh80UYxNuaDWhIGQYNQ96IuCg-AYWqNPjpU         Julius NM   \n",
      "1  LZQPQhLyRh_C2cTtd9MvFRJedxydaVW-2sNg5Diuo4A       adam riyati   \n",
      "2  LZQPQhLyRh9MSZYnf8djyk0gEF9BHDPYrrK-qCczIY8  Evgeny Murashkin   \n",
      "3          z13jhp0bxqncu512g22wvzkasxmvvzjaz04   ElNino Melendez   \n",
      "4          z13fwbwp1oujthgqj04chlngpvzmtt3r3dw            GsMega   \n",
      "5  LZQPQhLyRh9-wNRtlZDM90f1k0BrdVdJyN_YsaSwfxc      Jason Haddad   \n",
      "6          z13lfzdo5vmdi1cm123te5uz2mqig1brz04    ferleck ferles   \n",
      "7        z122wfnzgt30fhubn04cdn3xfx2mxzngsl40k      Bob Kanowski   \n",
      "8          z13ttt1jcraqexk2o234ghbgzxymz1zzi04              Cony   \n",
      "9          z12avveb4xqiirsix04chxviiljryduwxg0       BeBe Burkey   \n",
      "\n",
      "                  DATE                                            CONTENT  \\\n",
      "0  2013-11-07T06:20:48  Huh, anyway check out this you[tube] channel: ...   \n",
      "1  2013-11-07T12:37:15  Hey guys check out my new channel and our firs...   \n",
      "2  2013-11-08T17:34:21             just for test I have to say murdev.com   \n",
      "3  2013-11-09T08:28:43   me shaking my sexy ass on my channel enjoy ^_^ ﻿   \n",
      "4  2013-11-10T16:05:38            watch?v=vtaRGgvGtWQ   Check this out .﻿   \n",
      "5  2013-11-26T02:55:11  Hey, check out my new website!! This site is a...   \n",
      "6  2013-11-27T21:39:24                          Subscribe to my channel ﻿   \n",
      "7  2013-11-28T12:33:27  i turned it on mute as soon is i came on i jus...   \n",
      "8  2013-11-28T16:01:47    You should check my channel for Funny VIDEOS!!﻿   \n",
      "9  2013-11-28T16:30:13  and u should.d check my channel and tell me wh...   \n",
      "\n",
      "   CLASS  \n",
      "0      1  \n",
      "1      1  \n",
      "2      1  \n",
      "3      1  \n",
      "4      1  \n",
      "5      1  \n",
      "6      1  \n",
      "7      0  \n",
      "8      1  \n",
      "9      1  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 350 entries, 0 to 349\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   COMMENT_ID  350 non-null    object\n",
      " 1   AUTHOR      350 non-null    object\n",
      " 2   DATE        350 non-null    object\n",
      " 3   CONTENT     350 non-null    object\n",
      " 4   CLASS       350 non-null    int64 \n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 13.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset and take a look at the first 10 rows\n",
    "df = pd.read_csv(\"Youtube01-Psy.csv\")\n",
    "print(df.head(10))\n",
    "\n",
    "# Check for data types and missing values\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Data Preprocessing\n",
    "We only need the CONTENT and CLASS columns for this task. We will remove any unnecessary columns and also map the CLASS values from 0 and 1 to \"Not Spam\" and \"Spam\" for better readability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             CONTENT  CLASS\n",
      "0  Huh, anyway check out this you[tube] channel: ...      1\n",
      "1  Hey guys check out my new channel and our firs...      1\n",
      "2             just for test I have to say murdev.com      1\n",
      "3   me shaking my sexy ass on my channel enjoy ^_^ ﻿      1\n",
      "4            watch?v=vtaRGgvGtWQ   Check this out .﻿      1\n",
      "5  Hey, check out my new website!! This site is a...      1\n",
      "6                          Subscribe to my channel ﻿      1\n",
      "7  i turned it on mute as soon is i came on i jus...      0\n",
      "8    You should check my channel for Funny VIDEOS!!﻿      1\n",
      "9  and u should.d check my channel and tell me wh...      1\n"
     ]
    }
   ],
   "source": [
    "# Keep only relevant columns: 'CONTENT' and 'CLASS'\n",
    "df = df[[\"CONTENT\", \"CLASS\"]]\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             CONTENT     CLASS\n",
      "0  Huh, anyway check out this you[tube] channel: ...      Spam\n",
      "1  Hey guys check out my new channel and our firs...      Spam\n",
      "2             just for test I have to say murdev.com      Spam\n",
      "3   me shaking my sexy ass on my channel enjoy ^_^ ﻿      Spam\n",
      "4            watch?v=vtaRGgvGtWQ   Check this out .﻿      Spam\n",
      "5  Hey, check out my new website!! This site is a...      Spam\n",
      "6                          Subscribe to my channel ﻿      Spam\n",
      "7  i turned it on mute as soon is i came on i jus...  Not Spam\n",
      "8    You should check my channel for Funny VIDEOS!!﻿      Spam\n",
      "9  and u should.d check my channel and tell me wh...      Spam\n"
     ]
    }
   ],
   "source": [
    "# Map 'CLASS' from 0 and 1 to 'Not Spam' and 'Spam' for better understanding\n",
    "df[\"CLASS\"] = df[\"CLASS\"].map({0: \"Not Spam\", 1: \"Spam\"})\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Feature Extraction\n",
    "Since machine learning models can't work directly with text data, we need to convert the comments (text data) into a numerical form. For this, we use CountVectorizer from Scikit-learn, which converts the text into a matrix of token counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert text data to numerical form using CountVectorizer\n",
    "x = np.array(df[\"CONTENT\"])  # Features (comments)\n",
    "y = np.array(df[\"CLASS\"])    # Labels (Spam or Not Spam)\n",
    "\n",
    "# Vectorize the text data\n",
    "cv = CountVectorizer()\n",
    "x = cv.fit_transform(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Train-Test Split\n",
    "We split the dataset into training and test sets. The training set will be used to train the model, and the test set will be used to evaluate its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets (67% training, 33% testing)\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Model Training: Bernoulli Naive Bayes\n",
    "We are using the Bernoulli Naive Bayes model for classification. This model is well-suited for binary/boolean features, which makes it a good fit for this spam detection task where each word in the comment is treated as either present (1) or absent (0) in the comment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9913793103448276\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Bernoulli Naive Bayes model and train it\n",
    "model = BernoulliNB()\n",
    "model.fit(xtrain, ytrain)\n",
    "\n",
    "# Evaluate the model using the test set and print the accuracy score\n",
    "print(model.score(xtest, ytest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Model Testing with New Data\n",
    "We can now use the trained model to predict whether a new comment is spam or not. Below are two examples: one with a spam comment and one with a non-spam comment.\n",
    "\n",
    "Example 1: Testing with a Spam Comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Spam']\n"
     ]
    }
   ],
   "source": [
    "# Test the model with a sample spam comment\n",
    "df_sample = \"Hey! Check out my new website https://abc123.com\"\n",
    "df = cv.transform([df_sample]).toarray()\n",
    "print(model.predict(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example 2: Testing with a Non-Spam Comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Not Spam']\n"
     ]
    }
   ],
   "source": [
    "# Test the model with a sample non-spam comment\n",
    "df_sample = \"This video is very insightful!\"\n",
    "df = cv.transform([df_sample]).toarray()\n",
    "print(model.predict(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "In this project, we successfully built a model to detect spam comments on YouTube using the Bernoulli Naive Bayes algorithm. We started by importing and exploring the dataset, followed by data preprocessing, feature extraction using CountVectorizer, and model training. The BernoulliNB model was chosen because of its efficiency with binary features, making it an excellent choice for text-based classification tasks like spam detection. The model achieved a reasonable accuracy and was able to classify both spam and non-spam comments correctly."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
